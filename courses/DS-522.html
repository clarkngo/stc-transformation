<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DS 522: Data Acquisition & Analytics - Proposed Assessments</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 20px; background-color: #f4f4f4; }
        .container { max-width: 900px; margin: auto; background-color: #fff; padding: 30px; border-radius: 8px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }
        h1 { color: #e67e22; border-bottom: 2px solid #f39c12; padding-bottom: 10px; margin-bottom: 30px; }
        h2 { color: #f39c12; margin-top: 30px; border-bottom: 1px solid #eee; padding-bottom: 5px; }
        h3 { color: #2980b9; margin-top: 20px; }
        .example-box { background-color: #e8f8f5; border-left: 5px solid #1abc9c; padding: 15px; margin-bottom: 20px; border-radius: 4px; }
        ul { list-style-type: disc; margin-left: 20px; }
        li { margin-bottom: 8px; }
        strong { color: #34495e; }
    </style>
</head>
<body>
    <div class="container">
        <h1>DS 522: Data Acquisition and Analytics - Proposed Assessments</h1>
        <p><strong>Course Description:</strong> Covers methods for collecting, cleaning, and transforming raw data from various sources (APIs, web scraping, databases) and performing initial exploratory data analysis to extract insights.</p>

        <h2>1. Applied Case Studies / Conceptual Assessment (40%)</h2>
        <h3>Example Scenario: Analyzing Local Community Health Data</h3>
        <div class="example-box">
            <p><strong>Prompt:</strong> A local public health initiative needs to understand the factors affecting childhood obesity in San Diego County. Identify at least three distinct, publicly available data sources (e.g., CDC APIs, local government health datasets, environmental data). Prepare a <strong>data acquisition plan (4-5 pages) and an initial exploratory data analysis (EDA) report (visualizations only)</strong>. Your plan/report must:</p>
            <ul>
                <li>Detail the data acquisition strategy for each source (e.g., API calls, web scraping methodology).</li>
                <li>Outline the necessary data cleaning and transformation steps.</li>
                <li>Present 5-7 key visualizations highlighting potential correlations or trends relevant to childhood obesity in San Diego County.</li>
            </ul>
            <p><strong>Why AI-Resistant?</strong> Requires creative identification and ethical acquisition of diverse, specific real-world data sources, complex data cleaning strategies, and contextualized exploratory analysis. While AI can provide generic code, the critical judgment in selecting relevant data, applying specialized cleaning rules, and interpreting local health trends is human-driven.</p>
        </div>
        
        <h3>Example Viva Questions (Post-Submission)</h3>
        <div class="example-box">
            <ul>
                <li>"You chose to integrate Data Source A and Data Source B. What specific data quality issue did you anticipate during the merge, and what **Hands-On Skills (HOS)** (e.g., SQL joins, Pandas merging) did you use to resolve it?"</li>
                <li>"Your EDA report shows a correlation between X and Y. Explain a potential confounding variable you considered, and why it might alter the interpretation of this correlation."</li>
                <li>"How might an **AI Agent** assist you in drafting Python code for web scraping, and what specific legal or ethical considerations did you critically verify before executing the AI's suggested code?"</li>
            </ul>
        </div>

        <h2>2. Team Project: Building a Data Acquisition & EDA Pipeline (40%)</h2>
        <h3>Example Scenario: Real-time Public Transportation Analysis</h3>
        <div class="example-box">
            <p><strong>Prompt:</strong> Your team is tasked with building a system to collect and analyze real-time public transportation data for a specific metropolitan area (e.g., San Diego MTS, LA Metro). The system should:</p>
            <ul>
                <li>Acquire real-time data from at least one public API (e.g., GTFS-Realtime feeds).</li>
                <li>Store the raw and cleaned data in a suitable format (e.g., CSV, Parquet, simple database).</li>
                <li>Perform continuous exploratory data analysis to identify delays, route efficiency, and rider patterns.</li>
            <li>Present key findings in a simple, automatically updating dashboard.</li>
            </ul>
            <p>Your <strong>Project Portfolio</strong> must include the functional data pipeline, detailed **architecture diagrams** (showing data flow, storage), comprehensive code, and individual reflections on challenges and **AI Agent** usage.</p>
            <p><strong>Why AI-Resistant?</strong> Requires integrating multiple components (API ingestion, storage, cleaning, EDA, visualization) into a continuous pipeline. While AI can provide code snippets, building, debugging, and documenting a robust real-time data pipeline that handles streaming data and performs ongoing analysis is a complex engineering task demanding significant **Hands-On Skills (HOS)**.</p>
        </div>

        <h3>Example Viva Questions (Post-Submission)</h3>
        <div class="example-box">
            <ul>
                <li>"Your pipeline handles streaming data. What was the most challenging aspect of ensuring data quality in real-time, and what specific **Hands-On Skills (HOS)** (e.g., error handling, data validation) did your team use to address it?"</li>
                <li>"Explain the trade-offs your team considered in choosing your data storage solution (e.g., relational vs. NoSQL) for the real-time public transport data."</li>
            </ul>
        </div>

        <h2>3. Programming Exercises (PE) (20%)</h2>
        <h3>Example Scenario: Advanced Data Cleaning & Imputation</h3>
        <div class="example-box">
            <p><strong>Prompt:</strong> Given a highly problematic dataset (e.g., sensor data with anomalous spikes, missing values, inconsistent units, and categorical data needing encoding), your task is to:</p>
            <ul>
                <li>Implement a comprehensive data cleaning and imputation script using Python.</li>
                <li>Justify each cleaning step with statistical or domain-specific reasoning.</li>
                <li>Submit the cleaned dataset, the Python script, and a **Prompt Engineering Log & Reflection** detailing your use of **AI Agents** to explore different cleaning techniques, generate code for transformations, and identify hidden issues in the raw data. Include your critical evaluation of the AI's suggestions and any corrections you made.</li>
            </ul>
            <p><strong>Why AI-Resistant?</strong> Focuses on the nuanced, iterative process of real-world data cleaning, where human judgment and **Hands-On Skills (HOS)** are paramount. While AI can suggest code, the student must apply critical thinking to discern subtle data errors, justify complex imputation strategies, and ensure the cleaned data is appropriate for subsequent **Machine Learning** or analytical tasks.</p>
        </div>
        
        <h3>Example PE-Related Discussion Questions (Class Forum / Instructor Check-in)</h3>
        <div class="example-box">
            <ul>
                <li>"Describe a specific instance where an **AI Agent's** suggestion for handling outliers was statistically inappropriate for your dataset, and how your **Hands-On Skills (HOS)** in statistics helped you choose a better method."</li>
                <li>"What prompt did you use to ask the AI to identify 'unusual patterns' in your raw data, and how did that lead you to a specific cleaning step?"</li>
            </ul>
        </div>
    </div>
</body>
</html>